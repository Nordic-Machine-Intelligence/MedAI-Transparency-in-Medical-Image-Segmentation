{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-18T05:30:46.302999Z",
     "iopub.status.busy": "2021-08-18T05:30:46.302694Z",
     "iopub.status.idle": "2021-08-18T05:30:48.092655Z",
     "shell.execute_reply": "2021-08-18T05:30:48.091722Z",
     "shell.execute_reply.started": "2021-08-18T05:30:46.302948Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import jaccard_score\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#                                    #\n",
    "# Add your path to the data set here #\n",
    "#                                    #\n",
    "######################################\n",
    "\n",
    "file_list = np.asarray(os.listdir(\"./Kvasir-SEG/images\"))\n",
    "image_path = \"./Kvasir-SEG/images/\" \n",
    "mask_path = \"./Kvasir-SEG/masks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T05:30:48.095250Z",
     "iopub.status.busy": "2021-08-18T05:30:48.094906Z",
     "iopub.status.idle": "2021-08-18T05:30:48.102639Z",
     "shell.execute_reply": "2021-08-18T05:30:48.101436Z",
     "shell.execute_reply.started": "2021-08-18T05:30:48.095196Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the data into python in batches by using this batch generator\n",
    "\n",
    "def batch_generator(batch_size, gen_x): \n",
    "    batch_features = np.zeros((batch_size,256,256,3))\n",
    "    batch_labels = np.zeros((batch_size,256,256,3)) \n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            batch_features[i] , batch_labels[i] = next(gen_x)\n",
    "\n",
    "            yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T05:30:48.104830Z",
     "iopub.status.busy": "2021-08-18T05:30:48.104268Z",
     "iopub.status.idle": "2021-08-18T05:30:48.118329Z",
     "shell.execute_reply": "2021-08-18T05:30:48.117251Z",
     "shell.execute_reply.started": "2021-08-18T05:30:48.104759Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function generates data for trainig and validation\n",
    "\n",
    "def generate_data(filelist, img_path, mask_path, gen_type = \"train\"):\n",
    "    while True:\n",
    "        for i in filelist:\n",
    "            X_train = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n",
    "            X_train = cv2.resize(X_train, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "            y_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n",
    "            y_mask = cv2.resize(y_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n",
    "            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "            y_mask = (y_mask/255).astype(int)\n",
    "            yield X_train, y_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T05:30:48.121204Z",
     "iopub.status.busy": "2021-08-18T05:30:48.120420Z",
     "iopub.status.idle": "2021-08-18T05:30:48.133747Z",
     "shell.execute_reply": "2021-08-18T05:30:48.132521Z",
     "shell.execute_reply.started": "2021-08-18T05:30:48.121131Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function imports data for testing\n",
    "\n",
    "def generate_data_pred(filelist, img_path, mask_path, gen_type = \"train\"):\n",
    "    while True:\n",
    "        for i in filelist:\n",
    "            original_img = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n",
    "            X_train = cv2.resize(original_img, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "            original_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n",
    "            y_mask = cv2.resize(original_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n",
    "            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "            y_mask = (y_mask/255).astype(int)\n",
    "            yield original_img, original_mask, X_train, y_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T05:30:48.139248Z",
     "iopub.status.busy": "2021-08-18T05:30:48.138567Z",
     "iopub.status.idle": "2021-08-18T05:30:48.150116Z",
     "shell.execute_reply": "2021-08-18T05:30:48.147170Z",
     "shell.execute_reply.started": "2021-08-18T05:30:48.138986Z"
    }
   },
   "outputs": [],
   "source": [
    "# computes the dice score \n",
    "# # The code is taken from: https://www.programcreek.com/python/?CodeExample=compute+dice\n",
    "# Project: surface-distance   Author: deepmind  License: Apache License 2.0\n",
    "\n",
    "def dice_score(mask_gt, mask_pred):\n",
    "    \"\"\"Computes soerensen-dice coefficient.\n",
    "\n",
    "    compute the soerensen-dice coefficient between the ground truth mask `mask_gt`\n",
    "    and the predicted mask `mask_pred`.\n",
    "\n",
    "    Args:\n",
    "    mask_gt: 3-dim Numpy array of type bool. The ground truth mask.\n",
    "    mask_pred: 3-dim Numpy array of type bool. The predicted mask.\n",
    "\n",
    "    Returns:\n",
    "    the dice coeffcient as float. If both masks are empty, the result is NaN.\n",
    "    \"\"\"\n",
    "    volume_sum = mask_gt.sum() + mask_pred.sum()\n",
    "    if volume_sum == 0:\n",
    "        return np.NaN\n",
    "    volume_intersect = (mask_gt & mask_pred).sum()\n",
    "    return 2*volume_intersect / volume_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T05:30:48.153140Z",
     "iopub.status.busy": "2021-08-18T05:30:48.152508Z",
     "iopub.status.idle": "2021-08-18T05:30:49.907338Z",
     "shell.execute_reply": "2021-08-18T05:30:49.906530Z",
     "shell.execute_reply.started": "2021-08-18T05:30:48.152934Z"
    }
   },
   "outputs": [],
   "source": [
    "# These two functions can be used to implement the Dice loss\n",
    "# The code is taken from: https://gist.github.com/wassname/7793e2058c5c9dacb5212c0ac0b18a8a\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T05:30:49.911872Z",
     "iopub.status.busy": "2021-08-18T05:30:49.911566Z",
     "iopub.status.idle": "2021-08-18T05:30:49.918097Z",
     "shell.execute_reply": "2021-08-18T05:30:49.917335Z",
     "shell.execute_reply.started": "2021-08-18T05:30:49.911821Z"
    }
   },
   "outputs": [],
   "source": [
    "# These two functions can be used to implement the Jaccard loss\n",
    "\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return 1-jacard_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T05:45:55.142387Z",
     "iopub.status.busy": "2021-08-18T05:45:55.142045Z",
     "iopub.status.idle": "2021-08-18T05:45:55.162258Z",
     "shell.execute_reply": "2021-08-18T05:45:55.161323Z",
     "shell.execute_reply.started": "2021-08-18T05:45:55.142319Z"
    }
   },
   "outputs": [],
   "source": [
    "# A Unet architechture taken from: https://keras.io/examples/vision/oxford_pets_image_segmentation/ \n",
    "\n",
    "def Unet(img_size, num_classes):\n",
    "    inputs = tf.keras.Input(shape=img_size + (3,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = tf.keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = tf.keras.layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "        x = tf.keras.layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = tf.keras.layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = tf.keras.layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-18T05:46:02.872380Z",
     "iopub.status.busy": "2021-08-18T05:46:02.872001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/90 [====================>.........] - ETA: 2:05 - loss: 0.7006 - jacard_coef: 0.2994 - dice_coef: 0.8481"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters and other variables\n",
    "batchsize = 10\n",
    "data_size = len(file_list)\n",
    "num_epoch = 1\n",
    "\n",
    "# K-fold splits\n",
    "splits = 10\n",
    "kf = KFold(n_splits=splits)\n",
    "valsize = data_size // splits\n",
    "trainsize = data_size - valsize\n",
    "\n",
    "data_num = np.arange(data_size)\n",
    "\n",
    "img_size = (256, 256)\n",
    "num_classes = 3\n",
    "\n",
    "# Arrays to store scores from each CV-fold\n",
    "validation_dice_original = np.zeros([valsize,splits])\n",
    "validation_dice_resized = np.zeros([valsize,splits])\n",
    "#validation_jaccard_original = np.zeros([valsize,splits])\n",
    "#validation_jaccard_resized = np.zeros([valsize,splits])\n",
    "\n",
    "# A couter to keep track of current CV-fold\n",
    "cv_count = 0\n",
    "\n",
    "for train_index, val_index in kf.split(data_num):\n",
    "    # Time each CV-fold\n",
    "    time_start = time.time()\n",
    "    # Define model\n",
    "    model = Unet(img_size, 3)\n",
    "    # Compile model\n",
    "    model.compile(optimizer='Adam', loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n",
    "    # Train model\n",
    "    model.fit(x=batch_generator(batchsize, generate_data(file_list[train_index], image_path, mask_path, gen_type = \"train\")), epochs=num_epoch, \n",
    "                            steps_per_epoch=(trainsize/batchsize), \n",
    "                            validation_steps=(valsize/batchsize),\n",
    "                            validation_data=batch_generator(batchsize, generate_data(file_list[val_index], image_path, mask_path, gen_type = \"val\")), \n",
    "                            validation_freq=1, \n",
    "                            verbose = 1, \n",
    "                            )\n",
    "    # Define validation/test generator\n",
    "    val_gen  = generate_data_pred(file_list[val_index], image_path, mask_path, gen_type = \"val\")\n",
    "    for i in range(valsize):\n",
    "        # Import one set of polyp image and mask - both as original and resized images\n",
    "        original_img, original_mask, X, y_true = next(val_gen)\n",
    "        # Get shape of original image\n",
    "        original_shape = original_img.shape\n",
    "        # Use the trained model to do prediction on the resized polyp image\n",
    "        y_pred = model.predict(np.expand_dims(X,0))\n",
    "        # Binarize prediction\n",
    "        _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n",
    "        y_pred = (y_pred_thr/255).astype(int)\n",
    "        # Score the model performance based on the predicted 256x256 mask\n",
    "        dice_resized = dice_score(y_true[:,:,0],y_pred)\n",
    "        #jaccard_resized = jaccard_score(y_true[:,:,0],y_pred, average=\"macro\")\n",
    "        \n",
    "        # Resize the predicted mask to the original size\n",
    "        y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\n",
    "        # Score the model performance based on the original size of the mask\n",
    "        dice_original = dice_score(original_mask[:,:,0],y_pred_original.astype(int)*255)\n",
    "        #jaccard_original = jaccard_score(original_mask[:,:,0],y_pred_original.astype(int)*255, average=\"macro\")\n",
    "        \n",
    "        # Keep the dice and jaccard scores from the current predicion\n",
    "        validation_dice_original[i,cv_count] = dice_original\n",
    "        validation_dice_resized[i,cv_count] = dice_resized\n",
    "        #validation_jaccard_original[i,cv_count] = jaccard_original\n",
    "        #validation_jaccard_resized[i,cv_count] = jaccard_resized\n",
    "        \n",
    "        # Plot 5 examples fom the validation data.\n",
    "        # The figure on the top left shows the image with an overlay of the ground truth mask \n",
    "        # The figure on the top right shows the image with an overlay of the predicted mask\n",
    "        # The figure on the bottom left shows ground truth mask\n",
    "        # The figure on the bottom left shows the predicted mask\n",
    "        if i < 5:\n",
    "            print(\"-------------------------------------------------------\")\n",
    "            print(\"Mask on top of image (overlay)\")\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(original_img, 'gray', interpolation='none')\n",
    "            plt.imshow(original_mask/255.0, 'jet', interpolation='none', alpha=0.4)\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(original_img, 'gray', interpolation='none')\n",
    "            plt.imshow(y_pred_original, 'jet', interpolation='none', alpha=0.4)\n",
    "            plt.show()\n",
    "            print(\"Only mask\")\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(original_mask/255.0, interpolation='none')\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(y_pred_original, interpolation='none')\n",
    "            plt.show()\n",
    "            print(\"-------------------------------------------------------\")\n",
    "\n",
    "    # Calculate the mean dice and jaccard scores for all predicion in this CV-fold\n",
    "    dice_resized_mean = validation_dice_resized[:,cv_count].mean()\n",
    "    dice_original_mean = validation_dice_original[:,cv_count].mean()\n",
    "    #jaccard_resized_mean = validation_jaccard_resized[:,cv_count].mean()\n",
    "    #jaccard_original_mean = validation_jaccard_original[:,cv_count].mean()\n",
    "        \n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"Mean validation DICE (on resized data):\", dice_resized_mean) \n",
    "    print(\"Mean validation DICE (on original data):\", dice_original_mean)\n",
    "    print(\"--------------------------------------\")\n",
    "    #print(\"Mean validation Jaccard (on resized data):\", jaccard_resized_mean) \n",
    "    #print(\"Mean validation Jaccard (on original data):\", jaccard_original_mean)\n",
    "    #print(\"--------------------------------------\")\n",
    "\n",
    "    #run[\"Jaccard Resized\"].log(jaccard_resized_mean)\n",
    "    #run[\"Jaccard Original\"].log(jaccard_original_mean)\n",
    "    cv_count +=1\n",
    "    runtime = time.time() - time_start \n",
    "    print('Runtime {}-fold: {} sec'.format(cv_count,runtime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
